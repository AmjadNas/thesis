{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "from multiprocessing import cpu_count\n",
    "from gensim.test.utils import get_tmpfile\n",
    "from gensim.parsing.preprocessing import remove_stopwords, strip_numeric, strip_non_alphanum, \\\n",
    "    strip_multiple_whitespaces, strip_tags, strip_short\n",
    "from os import listdir\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "core_count = cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"news\"\n",
    "path = f\"Thesis/{folder}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "WINDOW_SIZE = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _prepossess_data(u_path, language):\n",
    "    files = listdir(f\"{u_path}\")\n",
    "    for f_name in files:\n",
    "\n",
    "        with open(f\"{u_path}/{f_name}\", \"r\", encoding=\"utf-8\") as file:\n",
    "            if language == \"AR\":\n",
    "                for sentence in file.read().split(\"\\n\"):\n",
    "                    tokens = [token.strip() for token in sentence.split() if token.strip()]\n",
    "                    if len(tokens) > 0:\n",
    "                        yield tokens\n",
    "            else:\n",
    "                for sentence in file.read().split(\"\\n\"):\n",
    "                    strr = strip_short(\n",
    "                        remove_stopwords(\n",
    "                            strip_numeric(strip_non_alphanum(strip_tags(strip_multiple_whitespaces(sentence))))),\n",
    "                        minsize=2).lower()\n",
    "                    if strr != '':\n",
    "                        yield strr.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(name, u_path, language):\n",
    "    sentences = [file for file in _prepossess_data(u_path, language)]\n",
    "    word_index = dict()\n",
    "    # for each sentence replace words with emotion and generated \n",
    "    # words with orginial term\n",
    "    for sentence in sentences:\n",
    "        for index, word in enumerate(sentence):\n",
    "            if word in word2em.keys() and not word in mapped.keys():\n",
    "                emotions_arr = word2em[word]\n",
    "                if word in word_index.keys():\n",
    "                    sentence[index] = word2em[word][word_index[word]]\n",
    "                    word_index[word] = (word_index[word] + 1) % len(emotions_arr)\n",
    "                else:\n",
    "                    sentence[index] = word2em[word][0]\n",
    "                    word_index[word] = 1 % len(emotions_arr)\n",
    "            if word in mapped.keys():\n",
    "                sentence[index] = mapped[word]\n",
    "    try:\n",
    "        if len(sentences) > 0:\n",
    "            try:\n",
    "                model = Word2Vec.load(f\"../models/{name}.model\")\n",
    "                model.build_vocab(sentences, update=True)\n",
    "                model.train(sentences, total_examples=len(sentences), epochs=50)\n",
    "                model.save(f\"../models/{name}.model\")\n",
    "                model.wv.save(f\"../models/{name}.kv\")\n",
    "                del model\n",
    "            except FileNotFoundError:\n",
    "                model = Word2Vec(sentences, iter=50, workers=core_count, min_count=1, window=WINDOW_SIZE, sg=1, size=300)\n",
    "                get_tmpfile(f\"../models/{name}.model\")\n",
    "                get_tmpfile(f\"../models/{name}.kv\")\n",
    "                model.save(f\"../models/{name}.model\")\n",
    "                model.wv.save(f\"../models/{name}.kv\")\n",
    "                del model\n",
    "            print(f\"finished training model {name}\")\n",
    "        else:\n",
    "            raise ModelTrainFailed(\"provided files are empty!\")\n",
    "\n",
    "    except Exception as err:\n",
    "        print(f\"model {name} training failed due to the following error: {err}\")\n",
    "\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_results(name, words, nbers, language):\n",
    "    try:\n",
    "        model = Word2Vec.load(f\"../models/{name}.model\")\n",
    "        wv = KeyedVectors.load(f\"../models/{name}.kv\", mmap='r')\n",
    "#         x = model.wv\n",
    "#         del model\n",
    "#         terms = file.read().split()\n",
    "\n",
    "        results = dict()\n",
    "        for word in words:\n",
    "            d = dict()\n",
    "            lowered = word.lower()\n",
    "            for term in nbers:\n",
    "                if language != \"AR\":\n",
    "                    decoded = term.lower()\n",
    "                else:\n",
    "                    decoded = term\n",
    "\n",
    "                try:\n",
    "                    d[decoded] = wv.similarity(lowered, decoded)\n",
    "                except KeyError as err:\n",
    "                    d[decoded] = 0.0\n",
    "\n",
    "            results[lowered] = d\n",
    "\n",
    "        return results\n",
    "    except FileNotFoundError:\n",
    "        raise FileNotFoundError(f\"model with name {name} does not exist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_emotions(mapper, table):\n",
    "    data = dict()\n",
    "    sset = set(table.columns)\n",
    "    for k,v in mapper.items():\n",
    "        col = pd.Series([0.0]*table.shape[0])\n",
    "        i = 0\n",
    "        for item in v:\n",
    "            if item in sset:\n",
    "                col = col + table[item].values\n",
    "                i += 1\n",
    "        \n",
    "        if i == 0:\n",
    "            data[k] = col\n",
    "        else:\n",
    "            data[k] = col/i\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_results(terms_frequencies, col, model_name):\n",
    "    df = pd.DataFrame(data=fetch_results(model_name, terms_frequencies, col, \"AR\"))\n",
    "    df = df.loc[:, (df != 0).any(axis=0)]\n",
    "    df = df.loc[(df != 0).any(axis=1), :]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "em2words = dict()\n",
    "word2em = dict()\n",
    "for f_name in listdir(\"../emotion-lexicon-master/arb\"):\n",
    "    with open(f\"../emotion-lexicon-master/arb/{f_name}\", encoding=\"utf-8\") as file:\n",
    "        for word in file.read().split(\" \"):\n",
    "            w = word.strip()\n",
    "            if w in word2em.keys():\n",
    "                if f_name.split(\".\")[0] not in word2em[w]:\n",
    "                    word2em[w].append(f_name.split(\".\")[0])\n",
    "            else:\n",
    "                word2em[w] = [f_name.split(\".\")[0]]\n",
    "            if f_name.split(\".\")[0] in em2words.keys():\n",
    "                em2words[f_name.split(\".\")[0]].append(w)\n",
    "            else:\n",
    "                em2words[f_name.split(\".\")[0]] = []\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "word2em = None\n",
    "mapped = None\n",
    "with open(\"../transformed/json/mapper.json\", \"r\", encoding=\"utf-8\") as mp:\n",
    "    mapped = json.load(mp)\n",
    "    \n",
    "with open(\"../transformed/json/word2em.json\", \"r\", encoding=\"utf-8\") as fp:\n",
    "    word2em = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for v, k in em2words.items():\n",
    "    em2words[v] = set(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "controled_vocab = pd.read_excel(f\"../Thesis/emotions.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emotion_Terms</th>\n",
       "      <th>Unnamed: 1</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Trust_Terms</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "      <th>Unnamed: 6</th>\n",
       "      <th>Unnamed: 7</th>\n",
       "      <th>Trust_Terms_stemmed</th>\n",
       "      <th>Unnamed: 9</th>\n",
       "      <th>...</th>\n",
       "      <th>Unnamed: 13</th>\n",
       "      <th>political_Terms</th>\n",
       "      <th>political_stemmed</th>\n",
       "      <th>Unnamed: 16</th>\n",
       "      <th>political_generated</th>\n",
       "      <th>Unnamed: 18</th>\n",
       "      <th>filtered_political</th>\n",
       "      <th>Unnamed: 20</th>\n",
       "      <th>trsut</th>\n",
       "      <th>distrust</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>لجنه</td>\n",
       "      <td>حكومة</td>\n",
       "      <td>حكومه</td>\n",
       "      <td>NaN</td>\n",
       "      <td>اامحفظه=محافظه=</td>\n",
       "      <td>NaN</td>\n",
       "      <td>اخوان</td>\n",
       "      <td>NaN</td>\n",
       "      <td>استقامه</td>\n",
       "      <td>احتيال</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>إنبساط</td>\n",
       "      <td>InbsAT</td>\n",
       "      <td>high spirits</td>\n",
       "      <td>הנאה</td>\n",
       "      <td>استقامة</td>\n",
       "      <td>AstqAmp</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>استقامه</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>مملكه</td>\n",
       "      <td>السياسة</td>\n",
       "      <td>سياسه</td>\n",
       "      <td>NaN</td>\n",
       "      <td>اامحفظهك=محافظه=</td>\n",
       "      <td>NaN</td>\n",
       "      <td>اسلام</td>\n",
       "      <td>NaN</td>\n",
       "      <td>احلاف</td>\n",
       "      <td>اضلال</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>الفة</td>\n",
       "      <td>Alfp</td>\n",
       "      <td>Friendship</td>\n",
       "      <td>חברות</td>\n",
       "      <td>إحلاف</td>\n",
       "      <td>IHlAf (?)</td>\n",
       "      <td>Honesty</td>\n",
       "      <td>יושרה</td>\n",
       "      <td>احلاف</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>مستعمره</td>\n",
       "      <td>سياسي</td>\n",
       "      <td>سياسي</td>\n",
       "      <td>NaN</td>\n",
       "      <td>اامحفظهكم=محافظه=</td>\n",
       "      <td>NaN</td>\n",
       "      <td>جمهوريه</td>\n",
       "      <td>NaN</td>\n",
       "      <td>امانه</td>\n",
       "      <td>اغراء</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>امومة</td>\n",
       "      <td>Amwmp</td>\n",
       "      <td>Motherhood</td>\n",
       "      <td>אמהות</td>\n",
       "      <td>اَمانة</td>\n",
       "      <td>&gt;mAnp</td>\n",
       "      <td>Confidence/security</td>\n",
       "      <td>יושר</td>\n",
       "      <td>امانه</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>ملك</td>\n",
       "      <td>حزب</td>\n",
       "      <td>حزب</td>\n",
       "      <td>NaN</td>\n",
       "      <td>اامحفظهكما=محافظه=</td>\n",
       "      <td>NaN</td>\n",
       "      <td>جيش</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ائتمان</td>\n",
       "      <td>اغواء</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>اهتمام</td>\n",
       "      <td>AhtmAm</td>\n",
       "      <td>consideration</td>\n",
       "      <td>דאגה</td>\n",
       "      <td>ائتمان</td>\n",
       "      <td>A&lt;tmAn</td>\n",
       "      <td>Reliance</td>\n",
       "      <td>הסתמכות</td>\n",
       "      <td>ائتمان</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>امير</td>\n",
       "      <td>حركة</td>\n",
       "      <td>حركه</td>\n",
       "      <td>NaN</td>\n",
       "      <td>اامحفظهكن=محافظه=</td>\n",
       "      <td>NaN</td>\n",
       "      <td>حاكم</td>\n",
       "      <td>NaN</td>\n",
       "      <td>اتكال</td>\n",
       "      <td>تامر</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Emotion_Terms Unnamed: 1     Unnamed: 2 Unnamed: 3 Trust_Terms Unnamed: 5  \\\n",
       "0           NaN        NaN            NaN        NaN         NaN        NaN   \n",
       "1       إنبساط     InbsAT    high spirits       הנאה     استقامة    AstqAmp   \n",
       "2          الفة       Alfp     Friendship      חברות       إحلاف  IHlAf (?)   \n",
       "3         امومة      Amwmp     Motherhood      אמהות      اَمانة      >mAnp   \n",
       "4        اهتمام     AhtmAm  consideration       דאגה      ائتمان     A<tmAn   \n",
       "\n",
       "            Unnamed: 6 Unnamed: 7 Trust_Terms_stemmed  Unnamed: 9  ...  \\\n",
       "0                  NaN        NaN                 NaN         NaN  ...   \n",
       "1                  NaN        NaN            استقامه          NaN  ...   \n",
       "2              Honesty      יושרה              احلاف          NaN  ...   \n",
       "3  Confidence/security       יושר              امانه          NaN  ...   \n",
       "4             Reliance    הסתמכות             ائتمان          NaN  ...   \n",
       "\n",
       "   Unnamed: 13 political_Terms political_stemmed Unnamed: 16  \\\n",
       "0        لجنه            حكومة            حكومه          NaN   \n",
       "1       مملكه          السياسة            سياسه          NaN   \n",
       "2     مستعمره            سياسي            سياسي          NaN   \n",
       "3         ملك              حزب              حزب          NaN   \n",
       "4        امير            حركة              حركه          NaN   \n",
       "\n",
       "  political_generated Unnamed: 18  filtered_political Unnamed: 20     trsut  \\\n",
       "0     اامحفظه=محافظه=         NaN               اخوان         NaN  استقامه    \n",
       "1    اامحفظهك=محافظه=         NaN               اسلام         NaN    احلاف    \n",
       "2   اامحفظهكم=محافظه=         NaN             جمهوريه         NaN    امانه    \n",
       "3  اامحفظهكما=محافظه=         NaN                 جيش         NaN   ائتمان    \n",
       "4   اامحفظهكن=محافظه=         NaN                حاكم         NaN    اتكال    \n",
       "\n",
       "  distrust  \n",
       "0  احتيال   \n",
       "1   اضلال   \n",
       "2   اغراء   \n",
       "3   اغواء   \n",
       "4    تامر   \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "controled_vocab.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add all terms for mapping\n",
    "# trusted_terms = controled_vocab.Trust_Terms_stemmed.dropna()\n",
    "# col = set([term.strip() for term in trusted_terms])\n",
    "# col.update([term.strip() for term in controled_vocab.political_stemmed.dropna()])\n",
    "# mapped = dict()\n",
    "# for item in col:\n",
    "#     mapped[item] = item\n",
    "# for values in controled_vocab.political_generated.dropna():\n",
    "#     key, value, _ = values.split(\"=\")\n",
    "#     mapped[key] = value\n",
    "# for values in controled_vocab.Trust_Terms_generated.dropna():\n",
    "#     try:\n",
    "#         key, value, _ = values.split(\"=\")\n",
    "#         mapped[key] = value\n",
    "#     except Exception as s:\n",
    "#         s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "trusted_terms = controled_vocab.Trust_Terms_stemmed.dropna().append(controled_vocab.political_stemmed.dropna())\n",
    "c = set([term.strip() for term in trusted_terms])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ائتلافيه',\n",
       " 'ائتمان',\n",
       " 'اتحاديه',\n",
       " 'اتكال',\n",
       " 'احتيال',\n",
       " 'احلاف',\n",
       " 'اخلاص',\n",
       " 'اخوان',\n",
       " 'اداره',\n",
       " 'استقامه',\n",
       " 'اسلام',\n",
       " 'اشتراكيه',\n",
       " 'اضلال',\n",
       " 'اعتماد',\n",
       " 'اغراء',\n",
       " 'اغواء',\n",
       " 'اقتصاد',\n",
       " 'امانه',\n",
       " 'امبراطوريه',\n",
       " 'ايمان',\n",
       " 'برلمان',\n",
       " 'بيروقراطيه',\n",
       " 'تامر',\n",
       " 'تدليس',\n",
       " 'تزوير',\n",
       " 'تشريعي',\n",
       " 'تصديق',\n",
       " 'تضليل',\n",
       " 'تعريض',\n",
       " 'تعهد',\n",
       " 'تلاعب',\n",
       " 'تنفيذي',\n",
       " 'ثقه',\n",
       " 'جاسوس',\n",
       " 'جمعيه',\n",
       " 'جمهوريه',\n",
       " 'جيش',\n",
       " 'حاكم',\n",
       " 'حركه',\n",
       " 'حريه',\n",
       " 'حزب',\n",
       " 'حكومه',\n",
       " 'حنث',\n",
       " 'ختل',\n",
       " 'خدع',\n",
       " 'خدعه',\n",
       " 'خيانه',\n",
       " 'داهيه',\n",
       " 'دستور',\n",
       " 'دهاء',\n",
       " 'دوله',\n",
       " 'ديكتاتوريه',\n",
       " 'ديموقراطيه',\n",
       " 'رئيس',\n",
       " 'راسماليه',\n",
       " 'رده',\n",
       " 'زائف',\n",
       " 'زاره',\n",
       " 'زعيم',\n",
       " 'زير',\n",
       " 'سياسه',\n",
       " 'سياسي',\n",
       " 'شريعه',\n",
       " 'شموليه',\n",
       " 'شيخ',\n",
       " 'شيوخ',\n",
       " 'شيوعيه',\n",
       " 'صدق',\n",
       " 'عضو',\n",
       " 'عمده',\n",
       " 'عهد',\n",
       " 'غدر',\n",
       " 'غر',\n",
       " 'غرر',\n",
       " 'غش',\n",
       " 'فاء',\n",
       " 'فاسد',\n",
       " 'فساد',\n",
       " 'فسخ',\n",
       " 'فصيله',\n",
       " 'قائد',\n",
       " 'قانون',\n",
       " 'قضائي',\n",
       " 'قوميه',\n",
       " 'كذب',\n",
       " 'كيل',\n",
       " 'لاء',\n",
       " 'مؤامره',\n",
       " 'مؤسسه',\n",
       " 'مجلس',\n",
       " 'محافظ',\n",
       " 'مخابرات',\n",
       " 'مخاتله',\n",
       " 'مداهنه',\n",
       " 'مرشح',\n",
       " 'مسؤول',\n",
       " 'مستشار',\n",
       " 'مسلم',\n",
       " 'مسلمون',\n",
       " 'مسلمين',\n",
       " 'مصداقيه',\n",
       " 'مكر',\n",
       " 'منافس',\n",
       " 'منصب',\n",
       " 'منظمه',\n",
       " 'موالاه',\n",
       " 'نائب',\n",
       " 'ناخب',\n",
       " 'نصاب',\n",
       " 'نصب',\n",
       " 'نفاق',\n",
       " 'نقض عهد',\n",
       " 'نكث',\n",
       " 'وطن',\n",
       " 'وعد',\n",
       " 'يقين'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished training model Addustour 2000_2013\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folder = \"news\"\n",
    "train_model(\"Al_Wafd 2000_2013\", f\"../Thesis/{folder}/split/Al_Wafd 2000_2013\", \"AR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished training model Addustour\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folder = \"Addustour\"\n",
    "train_model(f\"{folder}\", f\"../Thesis/news/out/{folder}\", \"AR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished training model Akhbar_el_Yom\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folder = \"Akhbar_el_Yom\"\n",
    "train_model(folder, f\"../Thesis/news/out/{folder}\", \"AR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished training model Al Ahali\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folder = \"Al Ahali\"\n",
    "train_model(folder, f\"../Thesis/news/out/{folder}\", \"AR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished training model Al_Masry_Alyoum\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folder = \"Al_Masry_Alyoum\"\n",
    "train_model(folder, f\"../Thesis/news/out/{folder}\", \"AR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished training model Al_Shorouk\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folder = \"Al_Shorouk\"\n",
    "train_model(folder, f\"../Thesis/news/out/{folder}\", \"AR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished training model Al_Wafd\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folder = \"Al_Wafd\"\n",
    "train_model(folder, f\"../Thesis/news/out/{folder}\", \"AR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished training model Alfagr\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folder = \"Alfagr\"\n",
    "train_model(folder, f\"../Thesis/news/out/{folder}\", \"AR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished training model AlQuds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folder = \"AlQuds\"\n",
    "train_model(folder, f\"../Thesis/news/out/{folder}\", \"AR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished training model AlRay\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folder = \"AlRay\"\n",
    "train_model(folder, f\"../Thesis/news/out/{folder}\", \"AR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished training model EG_AlDostour\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folder = \"EG_AlDostour\"\n",
    "train_model(folder, f\"../Thesis/news/out/{folder}\", \"AR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished training model Youm 7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folder = \"Youm 7\"\n",
    "train_model(folder, f\"../Thesis/news/out/{folder}\", \"AR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished training model Muslims_2014_2020_2\n"
     ]
    }
   ],
   "source": [
    "folder = \"Muslims_2014_2020_2\"\n",
    "name = f\"w2v_lexicon_{folder}.xlsx\"\n",
    "train_model(folder, f\"../Thesis/news/split/{folder}\", \"AR\")\n",
    "create_results(em2words.keys(), c, folder).to_excel(f\"../lexicons/{name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished training model Muslims_2013\n"
     ]
    }
   ],
   "source": [
    "folder = \"Muslims_2013\"\n",
    "name = f\"w2v_lexicon_{folder}.xlsx\"\n",
    "train_model(folder, f\"../Thesis/news/split/{folder}\", \"AR\")\n",
    "create_results(em2words.keys(), c, folder).to_excel(f\"../lexicons/{name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished training model Goverment 2013_2020\n"
     ]
    }
   ],
   "source": [
    "folder = \"Goverment 2013_2020\"\n",
    "name = f\"w2v_lexicon_{folder}.xlsx\"\n",
    "train_model(folder, f\"../Thesis/news/split/{folder}\", \"AR\")\n",
    "create_results(em2words.keys(), c, folder).to_excel(f\"../lexicons/{name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished training model Goverment_2013\n"
     ]
    }
   ],
   "source": [
    "folder = \"Goverment_2013\"\n",
    "name = f\"w2v_lexicon_{folder}.xlsx\"\n",
    "train_model(folder, f\"../Thesis/news/split/{folder}\", \"AR\")\n",
    "create_results(em2words.keys(), c, folder).to_excel(f\"../lexicons/{name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished training model all\n"
     ]
    }
   ],
   "source": [
    "folder = \"all\"\n",
    "name = f\"w2v_lexicon_{folder}.xlsx\"\n",
    "train_model(folder, f\"../Thesis/news/split/Muslims_2013\", \"AR\")\n",
    "create_results(em2words.keys(), c, folder).to_excel(f\"../lexicons/{name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "folder = \"news\"\n",
    "name = f\"w2v_lexicon_Muslims_2013.xlsx\"\n",
    "train_model(\"Muslims_2013\", f\"../Thesis/{folder}/split/Muslims_2013\", \"AR\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_results(em2words.keys(), c, \"Muslims_2013\").to_excel(f\"../lexicons/Muslims_2013.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = create_results(em2words.keys(), c, \"Goverment 2013_2020\")\n",
    "for index in df.index:\n",
    "    x = df.loc[index]\n",
    "    df.loc[index] = x/np.linalg.norm(x)\n",
    "df.to_excel(f\"../lexicons/unit/Goverment 2013_2020.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished training model aaa\n"
     ]
    }
   ],
   "source": [
    "folder = \"aaa\"\n",
    "name = f\"w2v_lexicon_{folder}.xlsx\"\n",
    "train_model(folder, f\"C:/Users/Amjad Nassar/Desktop/aaa\", \"AR\")\n",
    "create_results(em2words.keys(), c, folder).to_excel(f\"../lexicons/{name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
